{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergiomora03/AdvancedTopicsAnalytics/blob/main/exercises/E7-TextSummary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise 7 - Text Summary\n",
        "\n",
        "**Estudiantes:**\n",
        "- Mili Galindo\n",
        "- Anguie Garcia\n",
        "- Sonia Ramirez\n",
        "- Lourdes Rodil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2NseOxJAIFM"
      },
      "source": [
        "## Instrucciones:\n",
        "\n",
        "Text summarization is important in the field of machine learning and natural language processing for several reasons:\n",
        "\n",
        "1. **Information Retrieval:** Text summarization helps users quickly grasp the main points or key information from a large document, making it easier to decide whether to read the full document or not. This is particularly valuable in scenarios where individuals are inundated with vast amounts of textual data, such as news articles, research papers, or social media posts.\n",
        "\n",
        "2. **Time Efficiency:** Summarization algorithms can process and generate summaries much faster than humans can read and summarize large texts. This saves time and allows users to focus their attention on the most relevant content.\n",
        "\n",
        "3. **Content Extraction:** Text summarization can automatically extract essential information from a document, enabling applications like content recommendation, keyword extraction, and topic modeling.\n",
        "\n",
        "4. **Content Generation:** Summarization models can be used to generate concise, coherent, and informative summaries for various purposes, such as creating abstracts for research papers, news article headlines, or social media post previews.\n",
        "\n",
        "5. **Multilingual Support:** Text summarization can be applied to texts in multiple languages, making it a valuable tool for global communication and information retrieval.\n",
        "\n",
        "6. **Personalization:** Summarization can be personalized to individual preferences. Machine learning models can learn from user feedback to generate summaries that align more closely with a user's interests and priorities.\n",
        "\n",
        "7. **Scalability:** As the volume of digital content continues to grow, automated summarization becomes crucial for scaling information processing and retrieval. Machine learning-based summarization models can adapt and handle large volumes of text efficiently.\n",
        "\n",
        "8. **Legal and Compliance:** In legal and regulatory contexts, automated summarization can help organizations review contracts, policies, and legal documents to ensure compliance and identify critical clauses or information.\n",
        "\n",
        "9. **Search Engine Optimization (SEO):** Summarized content can be used to create concise and engaging snippets for search engine results, improving the discoverability of web content.\n",
        "\n",
        "10. **Content Creation:** Summarization can be integrated into content creation tools, helping authors and content creators generate concise and informative content more efficiently.\n",
        "\n",
        "Overall, text summarization is an essential component of machine learning and natural language processing, enabling efficient information retrieval, content extraction, and content generation across a wide range of applications and industries. It plays a critical role in handling the ever-increasing amount of textual data available in the digital age."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0voj5DTPAukU"
      },
      "source": [
        "---\n",
        "Exercise:\n",
        "\n",
        "Now, as a data scientist expert in NLP, you are asked to create a model to be able to summarize text in Spanish. Your stakeholders will pass you an article and your model should summarize it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Instalacion de librerias**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Librerias - requests beautifulsoup4\n",
        "Se instalan las bibliotecas \"requests\" y \"beautifulsoup4\" son herramientas muy útiles para realizar tareas relacionadas con la web y el análisis de HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw-K8uOkAG95",
        "outputId": "9da1870c-45aa-4d54-cddf-4e4632507546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Libreria - transformers\n",
        "Se instalan las bibliotecas \"requests\" y \"beautifulsoup4\" son herramientas muy útiles para realizar tareas relacionadas con la web y el análisis de HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
            "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.7.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Librerias - Bert-extractive-summarizer translate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-extractive-summarizer in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.10.1)\n",
            "Requirement already satisfied: translate in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (3.6.1)\n",
            "Requirement already satisfied: transformers in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from bert-extractive-summarizer) (4.38.2)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from bert-extractive-summarizer) (1.3.0)\n",
            "Requirement already satisfied: spacy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from bert-extractive-summarizer) (3.7.4)\n",
            "Requirement already satisfied: click in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from translate) (8.0.4)\n",
            "Requirement already satisfied: lxml in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from translate) (4.9.2)\n",
            "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from translate) (2.31.0)\n",
            "Requirement already satisfied: libretranslatepy==2.1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from translate) (2.1.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from click->translate) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->translate) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->translate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->translate) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->translate) (2023.7.22)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-learn->bert-extractive-summarizer) (1.24.3)\n",
            "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-learn->bert-extractive-summarizer) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-learn->bert-extractive-summarizer) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-learn->bert-extractive-summarizer) (2.2.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy->bert-extractive-summarizer) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy->bert-extractive-summarizer) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy->bert-extractive-summarizer) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy->bert-extractive-summarizer) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy->bert-extractive-summarizer) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy->bert-extractive-summarizer) (5.2.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy->bert-extractive-summarizer) (4.65.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy->bert-extractive-summarizer) (1.10.8)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.1.2)\n",
            "Requirement already satisfied: setuptools in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy->bert-extractive-summarizer) (68.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy->bert-extractive-summarizer) (23.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.3.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers->bert-extractive-summarizer) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers->bert-extractive-summarizer) (0.21.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers->bert-extractive-summarizer) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers->bert-extractive-summarizer) (2022.7.9)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers->bert-extractive-summarizer) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers->bert-extractive-summarizer) (0.4.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers->bert-extractive-summarizer) (2024.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers->bert-extractive-summarizer) (4.7.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy->bert-extractive-summarizer) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy->bert-extractive-summarizer) (0.1.4)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy->bert-extractive-summarizer) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from jinja2->spacy->bert-extractive-summarizer) (2.1.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install bert-extractive-summarizer translate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Libreria - tf-keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-keras in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.16.0)\n",
            "Requirement already satisfied: tensorflow<2.17,>=2.16 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tf-keras) (2.16.1)\n",
            "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.16.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.10.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (23.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (4.25.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.31.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (68.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (4.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.0.5)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.31.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.24.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.38.4)\n",
            "Requirement already satisfied: rich in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.0.7)\n",
            "Requirement already satisfied: dm-tree in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2023.7.22)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.1.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install tf-keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Libreria - sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Adquision de los datos**\n",
        "\n",
        "Usando las librerias de \"BeautifulSoup\" y \"requests\" se descargo un articulo de la revista Times en la seccion de**TIME100 AI** donde se presenta a Geoffrey Hinton."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Geoffrey Hinton](Imagen_Geoffrey_Hinton.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Con el siguiente codigo se recupera el texto del articulo que tiene una longitud de **1.215**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hKs-JhtBwzf",
        "outputId": "325593e2-4ee2-4996-d97d-5d37c4441e38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Over the course of February, Geoffrey Hinton, one of the most influential AI researchers of the past 50 years, had a “slow eureka moment.”\n",
            "Hinton, 76, has spent his career trying to build AI systems that model the human brain, mostly in academia before joining Google in 2013. He had always believed that the brain was better than the machines that he and others were building, and that by making them more like the brain, they would improve. But in February, he realized “the digital intelligence we’ve got now may be better than the brain already. It’s just not scaled up quite as big.” \n",
            "Developers around the world are currently racing to build the biggest AI systems that they can. Given the current rate at which AI companies are increasing the size of models, it could be less than five years until AI systems have 100 trillion connections—roughly as many as there are between neurons in the human brain.\n",
            "Alarmed, Hinton left his post as VP and engineering fellow in May and gave a flurry of interviews in which he explained that he had left in order to be able to speak freely on the dangers of AI—and his regrets over helping bring that technology into existence. He worries about what could happen once AI systems are scaled up to the size of human brains—and the prospect of humanity being wiped out by the technology he helped create. “This stuff will get smarter than us and take over,” says Hinton. “And if you want to know what that feels like, ask a chicken.”\n",
            "Born and raised in England, Hinton comes from a long line of luminaries, with relatives including the mathematician Mary Everest Boole and logician George Boole, whose work is crucial to modern computer science; surgeon James Hinton; and surveyor George Everest, who gave his name to the mountain. \n",
            "The human brain always fascinated Hinton. As a Cambridge University undergraduate, he tried a range of subjects—physiology, physics, philosophy—before graduating with a degree in experimental psychology in 1970. He worked briefly as a carpenter before starting a Ph.D. in AI at the University of Edinburgh, then the U.K.’s only postgraduate program on the subject, in 1972.\n",
            "In the 1970s, artificial intelligence, after failing to live up to its postwar promise, was going through a period of dampened enthusiasm now referred to as the “AI winter.” In this unfashionable field, Hinton pursued an unpopular idea: AI systems known as neural networks, which mimicked the structure of the human brain. His thesis adviser urged him on a weekly basis to change his approach. Each time he replied, “Give me another six months and I’ll prove to you that it works.”\n",
            "Upon completion of his Ph.D., Hinton moved to the U.S., where more funding was available for his research. He published pathbreaking research, for which he was awarded the 2018 Turing Award, in posts at universities across the U.S., before eventually taking a professorship in computer science at the University of Toronto. Toronto has become Hinton’s home base; he travels relatively infrequently because back problems prevent him from sitting down. During car journeys he lies across the back seat; he eats kneeling before a table “like a monk at the altar”; and as he spoke to TIME he swayed gently in front of a head-height camera.\n",
            "In 2012, Hinton and two of his graduate students, Alex Krizhevsky and Ilya Sutskever, now chief scientist at OpenAI, entered ImageNet, a once annual competition in which researchers competed to build the most accurate image-recognition AI systems. They dominated the competition—an emphatic demonstration that neural networks had come of age. Hinton’s persistence had paid off.\n",
            "He and his two students began receiving lucrative offers from big tech companies. They set up a shell company called DNN-research to auction their expertise, and four tech firms—Google, Microsoft, Baidu, and DeepMind—bid tens of millions for the company. After a week, Hinton chose Google over the final bidder, Baidu. In 2013, he joined Google Brain, the cutting-edge machine-learning team he left in May.\n",
            "Hinton has been instrumental in the development and popularization of neural networks, the dominant AI development paradigm that has allowed huge amounts of data to be ingested and processed, leading to advances in image recognition, language understanding, and self-driving cars. His work has potentially hastened the future he fears, in which AI becomes superhuman with disastrous results for humans. In an interview with the New York Times, Hinton said, “I console myself with the normal excuse: If I hadn’t done it, somebody else would have.”\n",
            "Hinton does not know how to prevent superhuman AI systems from taking over. If there’s any hope, he says, it lies with the next generation, noting that he feels too old to continue contributing to research. Many scientists switch to policy work later in their careers, but he declined Google’s offer to take such a role at the company. “I’ve never been very good at or interested in policy issues,” he tells TIME. “I’m a scientist.” \n",
            "Instead, Hinton has spent the past few months sounding the alarm—he can explain the technical details of AI in an accessible way as well as anyone and spends much of his time giving interviews to raise public awareness. He has also spoken with policymakers, including officials in the U.K. Prime Minister’s office, Canadian Prime Minister Justin Trudeau, Executive Vice-President of the European Commission Margrethe Vestager, and U.S. Senators Bernie Sanders and Jon Ossoff.\n",
            "While on a theoretical level he now grasps the risks from AI, Hinton says that his emotions haven’t yet caught up. “The idea that we’re going to be replaced as the apex intelligence is just very hard to get your head around.” \n",
            "But for now, he takes his cues from another relative: his cousin Joan Hinton was one of the only women scientists to work on the Manhattan Project. After the nuclear weapons that she helped to create were dropped on Hiroshima and Nagasaki, she became a peace activist. In 1948 she moved to China, and she spent most of the rest of her life working on dairy farms as an ardent Maoist. Hinton’s own retirement plans are less strident but likewise bucolic: he intends to rediscover carpentry and take long walks.\n",
            "Write to Will Henshall at will.henshall@time.com.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL del artículo\n",
        "url = \"https://time.com/collection/time100-ai/6309026/geoffrey-hinton/\"\n",
        "\n",
        "# Realizar una solicitud HTTP para obtener el contenido de la página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verificar si la solicitud fue exitosa\n",
        "if response.status_code == 200:\n",
        "    # Analizar el contenido HTML de la página con BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # Encontrar el contenido del artículo (puedes inspeccionar el HTML de la página para encontrar la estructura adecuada)\n",
        "    article_content = soup.find(\"div\", {\"class\": \"article-content\"})\n",
        "\n",
        "    # Extraer el texto del artículo\n",
        "    article_text = \"\"\n",
        "    for paragraph in article_content.find_all(\"p\"):\n",
        "        article_text += paragraph.get_text() + \"\\n\"\n",
        "\n",
        "    # Imprimir el texto del artículo\n",
        "    print(article_text)\n",
        "else:\n",
        "    print(\"Error al obtener la página:\", response.status_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de palabras: 1215\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "palabras = nltk.word_tokenize(article_text)\n",
        "num_palabras = len(palabras)\n",
        "print(\"Número de palabras:\", num_palabras)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Estratégia definida**\n",
        "Para mejorar la calidad del resumen al español se procede a realizar el resumen del texto en Ingles dado que es el orginen del texto y posteriormente a traducir del ingles al español el resumen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Resumen en ingles del texto**\n",
        "Se utiliza las librerias de transformers el modelo **\"t5-small\"**. En  summarizer ( modelo de aprendizaje automático diseñado específicamente para resumir texto de manera automática) donde se define como parametro un minimo de 100 y un maximmo de 200 palabras considerando un 8% y un 16% del tamaño del documento original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            " \u001b[1mResumén en Ingles\u001b[0m: \n",
            " 76-year-old geoffrey Hinton is one of the most influential AI researchers of the past 50 years. he has spent the past few months trying to build AI systems that model the human brain. his work has potentially hastened the future he fears, in which AI becomes superhuman with disastrous results for humans. \"this stuff will get smarter than us and take over,\" he says of his regrets over helping bring that technology into existence.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Especificar el modelo y la revisión\n",
        "model_name = \"t5-small\"\n",
        "model_revision = \"d769bba\"\n",
        "\n",
        "# Crear el pipeline de sumarización\n",
        "summarizer = pipeline(\"summarization\", model=model_name, revision=model_revision)\n",
        "\n",
        "# Generar el resumen del texto\n",
        "outputs = summarizer(article_text, min_length=100, max_length=200, clean_up_tokenization_spaces=True)\n",
        "\n",
        "# Extraer el resumen en inglés\n",
        "resumen_en = outputs[0]['summary_text']\n",
        "\n",
        "# Imprimir Resumen en Ingles\n",
        "print('\\n','\\n',\"\\033[1mResumén en Ingles\\033[0m:\",'\\n',resumen_en)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Traducción al Español de resumen en Ingles**\n",
        "\n",
        " En biblioteca de Hugging Face, el objeto pipeline puede ser utilizado para traducción de texto) donde se utilizo el modelo **\"Helsinki-NLP/opus-mt-en-es\"** para la traduccion del ingles al español. Como parametro se definio un minimo de 200 palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-es.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            " \u001b[1mResumén traducido al español\u001b[0m: \n",
            " Geoffrey Hinton, de 76 años, es uno de los investigadores de IA más influyentes de los últimos 50 años.Ha pasado los últimos meses tratando de construir sistemas de IA que modelen el cerebro humano.Su trabajo potencialmente ha acelerado el futuro que teme, en el que IA se vuelve sobrehumana con resultados desastrosos para los humanos. \"Esto se hará más inteligente que nosotros y asumirá el control\", dice de su pesar por ayudar a crear esa tecnología.\n"
          ]
        }
      ],
      "source": [
        "translator = pipeline(\"translation_en_to_de\",model=\"Helsinki-NLP/opus-mt-en-es\")\n",
        "outputs = translator(resumen_en, clean_up_tokenization_spaces=True, min_length=100)\n",
        "resumen_ES =(outputs[0]['translation_text'])\n",
        "\n",
        "# Imprimir la traducción del resumen\n",
        "print('\\n','\\n',\"\\033[1mResumén traducido al español\\033[0m:\",'\\n',resumen_ES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Resultado consolidado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            " \u001b[1mTexto Original\u001b[0m: \n",
            " Over the course of February, Geoffrey Hinton, one of the most influential AI researchers of the past 50 years, had a “slow eureka moment.”\n",
            "Hinton, 76, has spent his career trying to build AI systems that model the human brain, mostly in academia before joining Google in 2013. He had always believed that the brain was better than the machines that he and others were building, and that by making them more like the brain, they would improve. But in February, he realized “the digital intelligence we’ve got now may be better than the brain already. It’s just not scaled up quite as big.” \n",
            "Developers around the world are currently racing to build the biggest AI systems that they can. Given the current rate at which AI companies are increasing the size of models, it could be less than five years until AI systems have 100 trillion connections—roughly as many as there are between neurons in the human brain.\n",
            "Alarmed, Hinton left his post as VP and engineering fellow in May and gave a flurry of interviews in which he explained that he had left in order to be able to speak freely on the dangers of AI—and his regrets over helping bring that technology into existence. He worries about what could happen once AI systems are scaled up to the size of human brains—and the prospect of humanity being wiped out by the technology he helped create. “This stuff will get smarter than us and take over,” says Hinton. “And if you want to know what that feels like, ask a chicken.”\n",
            "Born and raised in England, Hinton comes from a long line of luminaries, with relatives including the mathematician Mary Everest Boole and logician George Boole, whose work is crucial to modern computer science; surgeon James Hinton; and surveyor George Everest, who gave his name to the mountain. \n",
            "The human brain always fascinated Hinton. As a Cambridge University undergraduate, he tried a range of subjects—physiology, physics, philosophy—before graduating with a degree in experimental psychology in 1970. He worked briefly as a carpenter before starting a Ph.D. in AI at the University of Edinburgh, then the U.K.’s only postgraduate program on the subject, in 1972.\n",
            "In the 1970s, artificial intelligence, after failing to live up to its postwar promise, was going through a period of dampened enthusiasm now referred to as the “AI winter.” In this unfashionable field, Hinton pursued an unpopular idea: AI systems known as neural networks, which mimicked the structure of the human brain. His thesis adviser urged him on a weekly basis to change his approach. Each time he replied, “Give me another six months and I’ll prove to you that it works.”\n",
            "Upon completion of his Ph.D., Hinton moved to the U.S., where more funding was available for his research. He published pathbreaking research, for which he was awarded the 2018 Turing Award, in posts at universities across the U.S., before eventually taking a professorship in computer science at the University of Toronto. Toronto has become Hinton’s home base; he travels relatively infrequently because back problems prevent him from sitting down. During car journeys he lies across the back seat; he eats kneeling before a table “like a monk at the altar”; and as he spoke to TIME he swayed gently in front of a head-height camera.\n",
            "In 2012, Hinton and two of his graduate students, Alex Krizhevsky and Ilya Sutskever, now chief scientist at OpenAI, entered ImageNet, a once annual competition in which researchers competed to build the most accurate image-recognition AI systems. They dominated the competition—an emphatic demonstration that neural networks had come of age. Hinton’s persistence had paid off.\n",
            "He and his two students began receiving lucrative offers from big tech companies. They set up a shell company called DNN-research to auction their expertise, and four tech firms—Google, Microsoft, Baidu, and DeepMind—bid tens of millions for the company. After a week, Hinton chose Google over the final bidder, Baidu. In 2013, he joined Google Brain, the cutting-edge machine-learning team he left in May.\n",
            "Hinton has been instrumental in the development and popularization of neural networks, the dominant AI development paradigm that has allowed huge amounts of data to be ingested and processed, leading to advances in image recognition, language understanding, and self-driving cars. His work has potentially hastened the future he fears, in which AI becomes superhuman with disastrous results for humans. In an interview with the New York Times, Hinton said, “I console myself with the normal excuse: If I hadn’t done it, somebody else would have.”\n",
            "Hinton does not know how to prevent superhuman AI systems from taking over. If there’s any hope, he says, it lies with the next generation, noting that he feels too old to continue contributing to research. Many scientists switch to policy work later in their careers, but he declined Google’s offer to take such a role at the company. “I’ve never been very good at or interested in policy issues,” he tells TIME. “I’m a scientist.” \n",
            "Instead, Hinton has spent the past few months sounding the alarm—he can explain the technical details of AI in an accessible way as well as anyone and spends much of his time giving interviews to raise public awareness. He has also spoken with policymakers, including officials in the U.K. Prime Minister’s office, Canadian Prime Minister Justin Trudeau, Executive Vice-President of the European Commission Margrethe Vestager, and U.S. Senators Bernie Sanders and Jon Ossoff.\n",
            "While on a theoretical level he now grasps the risks from AI, Hinton says that his emotions haven’t yet caught up. “The idea that we’re going to be replaced as the apex intelligence is just very hard to get your head around.” \n",
            "But for now, he takes his cues from another relative: his cousin Joan Hinton was one of the only women scientists to work on the Manhattan Project. After the nuclear weapons that she helped to create were dropped on Hiroshima and Nagasaki, she became a peace activist. In 1948 she moved to China, and she spent most of the rest of her life working on dairy farms as an ardent Maoist. Hinton’s own retirement plans are less strident but likewise bucolic: he intends to rediscover carpentry and take long walks.\n",
            "Write to Will Henshall at will.henshall@time.com.\n",
            " \n",
            " \n",
            " \u001b[1mResumén en Ingles\u001b[0m: \n",
            " 76-year-old geoffrey Hinton is one of the most influential AI researchers of the past 50 years. he has spent the past few months trying to build AI systems that model the human brain. his work has potentially hastened the future he fears, in which AI becomes superhuman with disastrous results for humans. \"this stuff will get smarter than us and take over,\" he says of his regrets over helping bring that technology into existence. \n",
            " \n",
            " \u001b[1mResumén traducido al español\u001b[0m: \n",
            " Geoffrey Hinton, de 76 años, es uno de los investigadores de IA más influyentes de los últimos 50 años.Ha pasado los últimos meses tratando de construir sistemas de IA que modelen el cerebro humano.Su trabajo potencialmente ha acelerado el futuro que teme, en el que IA se vuelve sobrehumana con resultados desastrosos para los humanos. \"Esto se hará más inteligente que nosotros y asumirá el control\", dice de su pesar por ayudar a crear esa tecnología.\n"
          ]
        }
      ],
      "source": [
        "# Se concatenan los resultados y se imprimen:\n",
        "print('\\n','\\n',\"\\033[1mTexto Original\\033[0m:\",'\\n',article_text,'\\n','\\n',\"\\033[1mResumén en Ingles\\033[0m:\",'\\n',resumen_en,'\\n','\\n',\"\\033[1mResumén traducido al español\\033[0m:\",'\\n',resumen_ES)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMk/du9ggsuzmUoZg99Ampu",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
